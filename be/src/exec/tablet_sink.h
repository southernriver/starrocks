// This file is made available under Elastic License 2.0.
// This file is based on code available under the Apache license here:
//   https://github.com/apache/incubator-doris/blob/master/be/src/exec/tablet_sink.h

// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//   http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.

#pragma once

#include <memory>
#include <queue>
#include <set>
#include <string>
#include <thread>
#include <unordered_map>
#include <utility>
#include <vector>

#include "common/object_pool.h"
#include "common/status.h"
#include "common/tracer.h"
#include "exec/data_sink.h"
#include "exec/tablet_info.h"
#include "exec/vectorized/tablet_info.h"
#include "exec/tablet_sink/tablet_sink_index_channel.h"
#include "exec/tablet_sink/tablet_sink_sender.h"
#include "gen_cpp/Types_types.h"
#include "gen_cpp/doris_internal_service.pb.h"
#include "gen_cpp/internal_service.pb.h"
#include "runtime/mem_tracker.h"
#include "util/bitmap.h"
#include "util/compression/block_compression.h"
#include "util/raw_container.h"
#include "util/ref_count_closure.h"
#include "util/reusable_closure.h"

namespace starrocks {

class Bitmap;
class MemTracker;
class RuntimeProfile;
class RowDescriptor;
class TupleDescriptor;
class ExprContext;
class TExpr;

namespace stream_load {

class AddBatchCounter;
class NodeChannel;
class IndexChannel;
class TabletSinkSender;

// Write data to Olap Table.
// When OlapTableSink::open() called, there will be a consumer thread running in the background.
// When you call OlapTableSink::send(), you will be the productor who products pending batches.
// Join the consumer thread in close().
class OlapTableSink : public DataSink {
public:
    // Construct from thrift struct which is generated by FE.
    OlapTableSink(ObjectPool* pool, const std::vector<TExpr>& texprs, Status* status);
    ~OlapTableSink() override = default;

    Status init(const TDataSink& sink, RuntimeState* state) override;

    Status prepare(RuntimeState* state) override;

    // sync open interface
    Status open(RuntimeState* state) override;

    // async open interface: try_open() -> [is_open_done()] -> open_wait()
    // if is_open_done() return true, open_wait() will not block
    // otherwise open_wait() will block
    Status try_open(RuntimeState* state);

    bool is_open_done();

    Status open_wait();

    // async add chunk interface
    // if is_full() return false, add_chunk() will not block
    Status send_chunk(RuntimeState* state, vectorized::Chunk* chunk) override;

    bool is_full();

    // async close interface: try_close() -> [is_close_done()] -> close_wait()
    // if is_close_done() return true, close_wait() will not block
    // otherwise close_wait() will block
    Status try_close(RuntimeState* state) { return _tablet_sink_sender->try_close(state); }

    Status close_wait(RuntimeState* state, Status close_status);

    bool is_close_done();

    // sync close() interface
    Status close(RuntimeState* state, Status close_status) override;

    // Returns the runtime profile for the sink.
    RuntimeProfile* profile() override { return _profile; }

    ObjectPool* pool() { return _pool; }

private:
    template <LogicalType PT>
    void _validate_decimal(RuntimeState* state, vectorized::Column* column, const SlotDescriptor* desc,
                           std::vector<uint8_t>* validate_selection);
    // This method will change _validate_selection
    void _validate_data(RuntimeState* state, vectorized::Chunk* chunk);

    Status _init_node_channels(RuntimeState* state);

    // When compute buckect hash, we should use real string for char column.
    // So we need to pad char column after compute buckect hash.
    void _padding_char_column(vectorized::Chunk* chunk);

    void _print_varchar_error_msg(RuntimeState* state, const Slice& str, SlotDescriptor* desc);

    static void _print_decimal_error_msg(RuntimeState* state, const DecimalV2Value& decimal, SlotDescriptor* desc);

    Status _fill_auto_increment_id(vectorized::Chunk* chunk);

    Status _fill_auto_increment_id_internal(vectorized::Chunk* chunk, SlotDescriptor* slot, int64_t table_id);

    void mark_as_failed(const NodeChannel* ch) { _failed_channels.insert(ch->node_id()); }
    bool is_failed_channel(const NodeChannel* ch) { return _failed_channels.count(ch->node_id()) != 0; }
    bool has_intolerable_failure() {
        if (_write_quorum_type == TWriteQuorumType::ALL) {
            return _failed_channels.size() > 0;
        } else if (_write_quorum_type == TWriteQuorumType::ONE) {
            return _failed_channels.size() >= _num_repicas;
        } else {
            return _failed_channels.size() >= ((_num_repicas + 1) / 2);
        }
    }

    void for_each_node_channel(const std::function<void(NodeChannel*)>& func) {
        for (auto& it : _node_channels) {
            func(it.second.get());
        }
    }

    void for_each_index_channel(const std::function<void(NodeChannel*)>& func) {
        for (auto& index_channel : _channels) {
            index_channel->for_each_node_channel(func);
        }
    }

    friend class NodeChannel;
    friend class IndexChannel;

    ObjectPool* _pool;
    int64_t _rpc_http_min_size = 0;

    // unique load id
    PUniqueId _load_id;
    int64_t _txn_id = -1;
    std::string _txn_trace_parent;
    Span _span;
    int _num_repicas = -1;
    bool _need_gen_rollup = false;
    int _tuple_desc_id = -1;
    std::string _merge_condition;

    // this is tuple descriptor of destination OLAP table
    TupleDescriptor* _output_tuple_desc = nullptr;
    std::vector<ExprContext*> _output_expr_ctxs;

    // number of senders used to insert into OlapTable, if we only support single node insert,
    // all data from select should collectted and then send to OlapTable.
    // To support multiple senders, we maintain a channel for each sender.
    int _sender_id = -1;
    int _num_senders = -1;
    bool _is_lake_table = false;

    TKeysType::type _keys_type;

    // TODO(zc): think about cache this data
    std::shared_ptr<OlapTableSchemaParam> _schema;
    vectorized::OlapTablePartitionParam* _vectorized_partition = nullptr;
    StarRocksNodesInfo* _nodes_info = nullptr;
    OlapTableLocationParam* _location = nullptr;

    std::vector<DecimalValue> _max_decimal_val;
    std::vector<DecimalValue> _min_decimal_val;

    std::vector<DecimalV2Value> _max_decimalv2_val;
    std::vector<DecimalV2Value> _min_decimalv2_val;

    // one chunk selection index for partition validation and data validation
    std::vector<uint16_t> _validate_select_idx;
    // one chunk selection for data validation
    std::vector<uint8_t> _validate_selection;

    RuntimeProfile* _profile = nullptr;

    // index_channel
    std::vector<std::unique_ptr<IndexChannel>> _channels;
    std::vector<vectorized::OlapTablePartition*> _partitions;
    std::unordered_map<int64_t, std::set<int64_t>> _index_id_partition_ids;
    std::vector<uint32_t> _tablet_indexes;
    // Store the output expr comput result column
    std::unique_ptr<vectorized::Chunk> _output_chunk;
    bool _open_done{false};

    std::unique_ptr<TabletSinkSender> _tablet_sink_sender;

    // Stats for this
    int64_t _convert_batch_ns = 0;
    int64_t _validate_data_ns = 0;
    int64_t _number_input_rows = 0;
    int64_t _number_output_rows = 0;
    int64_t _number_filtered_rows = 0;

    RuntimeProfile::Counter* _input_rows_counter = nullptr;
    RuntimeProfile::Counter* _output_rows_counter = nullptr;
    RuntimeProfile::Counter* _filtered_rows_counter = nullptr;
    RuntimeProfile::Counter* _prepare_data_timer = nullptr;
    RuntimeProfile::Counter* _send_data_timer = nullptr;
    RuntimeProfile::Counter* _convert_chunk_timer = nullptr;
    RuntimeProfile::Counter* _validate_data_timer = nullptr;
    RuntimeProfile::Counter* _open_timer = nullptr;
    RuntimeProfile::Counter* _close_timer = nullptr;
    RuntimeProfile::Counter* _serialize_chunk_timer = nullptr;
    RuntimeProfile::Counter* _wait_response_timer = nullptr;
    RuntimeProfile::Counter* _compress_timer = nullptr;
    RuntimeProfile::Counter* _pack_chunk_timer = nullptr;
    RuntimeProfile::Counter* _send_rpc_timer = nullptr;
    RuntimeProfile::Counter* _client_rpc_timer = nullptr;
    RuntimeProfile::Counter* _server_rpc_timer = nullptr;
    RuntimeProfile::Counter* _alloc_auto_increment_timer = nullptr;
    RuntimeProfile::Counter* _server_wait_flush_timer = nullptr;

    // load mem limit is for remote load channel
    int64_t _load_mem_limit = 0;

    // the timeout of load channels opened by this tablet sink. in second
    int64_t _load_channel_timeout_s = 0;

    // BeId -> channel
    std::unordered_map<int64_t, std::unique_ptr<NodeChannel>> _node_channels;
    // BeId
    std::set<int64_t> _failed_channels;
    // enable colocate index
    bool _colocate_mv_index = config::enable_load_colocate_mv;

    bool _enable_replicated_storage = false;

    TWriteQuorumType::type _write_quorum_type = TWriteQuorumType::MAJORITY;

    RuntimeState* _state = nullptr;
};

} // namespace stream_load
} // namespace starrocks
